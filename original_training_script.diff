
import os

from trainer import Trainer, TrainerArgs

from TTS.config.shared_configs import BaseDatasetConfig
from TTS.tts.configs.delightful_tts_config import DelightfulTtsAudioConfig, DelightfulTTSConfig
from TTS.tts.datasets import load_tts_samples
from TTS.tts.models.delightful_tts import DelightfulTtsArgs, DelightfulTTS, VocoderConfig
from TTS.tts.utils.text.tokenizer import TTSTokenizer
from TTS.utils.audio.processor import AudioProcessor

- data_path = ""
+ # This points to the "root" directory of the Common Voice dataâ€”the one that contains `validated.tsv`, `clips`, etc.
+ data_path = os.path.join("/home/u26/jmostoller/ondemand/ling696/cv-corpus-12.0-2022-12-07/nl") 
- output_path = os.path.dirname(os.path.abspath(__file__))
+ output_path = os.path.join("/xdisk/hahnpowell/jmostoller/") # Each model is output to its own directory on xdisk

dataset_config = BaseDatasetConfig(
-    dataset_name="ljspeech", 
-    formatter="ljspeech", 
+    formatter="common_voice", # Use the Common Voice auto-formatting to read the meta file/dataset as-is
-    meta_file_train="metadata.csv", 
+    # Change the training file to point to the `valitaded.tsv` file associated with the dataset:
+    meta_file_train="/home/u26/jmostoller/ondemand/ling696/cv-corpus-12.0-2022-12-07/nl/validated.tsv",
    path=data_path
)

audio_config = DelightfulTtsAudioConfig()
model_args = DelightfulTtsArgs()

vocoder_config = VocoderConfig()

delightful_tts_config = DelightfulTTSConfig(
+    run_name="delightful_tts_nl", # Custom run name set :)
+    run_description="Train on Dutch from CommonVoice",
    model_args=model_args,
    audio=audio_config,
    vocoder=vocoder_config,
-    batch_size=32,
+    # 32-sample batches were too big to even start training on, 
+    batch_size=16, 
+    eval_batch_size=16,
-    num_loader_workers=10,
-    num_eval_loader_workers=10,
-    precompute_num_workers=10,
+    # Coqui warned that my system was only able to use 1 worker, so I lowered all these values.
+    num_loader_workers=1,
+    num_eval_loader_workers=1,
+    precompute_num_workers=1,
-    batch_group_size=2,
+    batch_group_size=0, # Batch gruping seemed to be causing memory issues, so I opted out of it.
    compute_input_seq_cache=True,
    compute_f0=True,
-    f0_cache_path=os.path.join(output_path, "f0_cache"),
+    # Storing audio-related caches with the dataset helps reusability
+    f0_cache_path=os.path.join(data_path, "f0_cache"), 
    run_eval=True,
    test_delay_epochs=-1,
-    epochs=1000,
+    epochs=100, # Reduced the number of epochs; 100 is plenty!
-    text_cleaner="english_cleaners",
+    text_cleaner="phoneme_cleaners", # No built-in Dutch cleaner, so I used a more generic "phoneme" one
    use_phonemes=True,
-    phoneme_language="en-us",
+    phoneme_language="nl", # Use Dutch phonemes! ðŸ‡³ðŸ‡±
-    phoneme_cache_path=os.path.join(output_path, "phoneme_cache"),
+    phoneme_cache_path=os.path.join(data_path, "phoneme_cache"), # Cache phonemes with the dataset
-    print_step=50,
+    print_step=100, # Increase the print steps (there are a lot of steps!)
    print_eval=False,
    mixed_precision=True,
    output_path=output_path,
    datasets=[dataset_config],
    start_by_longest=False,
    eval_split_size=0.1,
    binary_align_loss_alpha=0.0,
    use_attn_priors=False,
-    lr_gen=4e-1,
-    lr=4e-1,
-    lr_disc=4e-1,
+    # These learning rates were *incredibly* high and would instantly lead to errors unless lowered.
+    lr_gen=4e-4,
+    lr=4e-4,
+    lr_disc=4e-4,
-    max_text_len=130, # I wasn't sure about the max text length, so I left it unspecified.
)

tokenizer, config = TTSTokenizer.init_from_config(delightful_tts_config)

ap = AudioProcessor.init_from_config(config)

train_samples, eval_samples = load_tts_samples(
    dataset_config,
    eval_split=True,
    eval_split_max_size=config.eval_split_max_size,
    eval_split_size=config.eval_split_size,
)

train_samples = train_samples
eval_samples = eval_samples

model = DelightfulTTS(ap=ap, config=config, tokenizer=tokenizer, speaker_manager=None)

trainer = Trainer(
    TrainerArgs(),
    config,
    output_path,
    model=model,
    train_samples=train_samples,
    eval_samples=eval_samples,
)

trainer.fit()